## 📘 통합 PRD: 초개인화 재난 대응 앱 ‘안전나침반’

-----

### 🧭 1. 서비스 정의 및 목표

#### **1.1. 핵심 가치**

"어떤 상황, 어떤 사람이든, 가장 정확하고 안전한 길을 안내한다."

#### **1.2. 서비스 목적**

'안전나침반'은 **①평시에 미리 입력받는 사용자의 고유 정보**와 **②재난 발생 시 추가로 입력받는 실시간 상황 정보**를 유기적으로 결합하여, 신뢰할 수 있는 정보를 바탕으로 초개인화된 재난(지진) 대응 매뉴얼을 제공하는 **PWA(Progressive Web App)** 입니다. 본 문서는 서비스의 성공적인 PoC 개발을 위한 요구사항을 정의합니다.

-----

### 🌟 2. 핵심 기능 요약 (MVP)

| 구분 | 기능 | 핵심 설명 |
| :--- | :--- | :--- |
| **Phase 1: 평시** | **사전 정보 등록 및 적응형 UI** | 나이, 성별, 언어, 동행 파트너, 접근성(시각/청각) 등 초기 정보를 DB에 저장하고, 이에 맞춰 UI/UX를 자동 최적화합니다. |
| **Phase 2: 재난** | **재난 감지 및 PUSH 알림** | 재난문자 API(모킹)에서 '지진'을 감지하면 즉시 사용자에게 PUSH 알림을 발송합니다. |
| | **실시간 상태 입력** | 사용자가 알림을 통해 앱에 진입하면 현재 위치(GPS), 실내/외 여부, 이동 가능성을 입력받습니다. |
| | **RAG 기반 초개인화 매뉴얼 생성** | \*\*[사전 정보 + 실시간 정보]\*\*를 종합하여 RAG 기술로 가장 신뢰도 높은 맞춤형 행동 요령을 생성합니다. |
| | **멀티모달(Multi-Modal) 안내** | 생성된 매뉴얼을 텍스트, 다국어 음성(TTS), 진동(햅틱) 등 사용자에게 최적화된 형태로 제공합니다. |
| | **스마트 대피소 안내** | T Map API를 연동하여 현재 위치에서 가장 가까운 대피소를 지도에 표시하고, 도보 경로를 안내합니다. |
| | **SOS 긴급 요청** | 클릭 한 번으로 사전 등록된 동행 파트너와 119에 구조 요청을 보냅니다. |
| | **다국어 지원** | 사용자의 언어 설정에 기반하여 모든 안내 메시지를 자동으로 번역하여 제공합니다. |

-----

### 🧱 3. 시스템 아키텍처 및 작동 흐름

#### **전체 흐름도**

```
[Phase 1: 평시]
사용자 (PWA 실행) -> 사전 정보 입력 (나이, 언어, 접근성 등) -> [Supabase DB]에 저장

[Phase 2: 재난]
[백엔드 서버 (FastAPI)] --(1. 주기적 모니터링)--> [재난문자 API]
      |
(2. '지진' 감지)
      ↓
[PWA Push 알림] -> 사용자에게 발송
      |
(3. 사용자 알림 클릭 & 앱 실행)
      ↓
[프론트엔드 (React PWA)]
- 실시간 상태 입력 (위치, 실내/외, 이동 가능성)
- Supabase에서 사전 정보 조회
      |
(4. [사전 정보 + 실시간 정보] 통합하여 API 요청)
      ↓
[백엔드 서버 (FastAPI)] <--> [Vector DB (Qdrant)] <--> [OpenAI GPT-4]
- RAG 파이프라인으로 맞춤 매뉴얼 생성
- T Map API로 주변 대피소 정보 결합
      |
(5. 최종 안내 데이터 응답)
      ↓
[프론트엔드 (React PWA)]
- 텍스트, 음성(TTS), 진동, 지도로 사용자에게 안내
```

-----

### 🔧 4. 기술 스택 및 외부 API

| 구분 | 기술 / API | 목적 및 비고 |
| :--- | :--- | :--- |
| **프론트엔드** | **React (PWA)** | Vite 기반. 웹 표준 기술로 빠른 배포 및 접근성 확보. |
| **백엔드** | **FastAPI (Python)** | 비즈니스 로직 및 RAG 파이프라인 실행. |
| **데이터베이스** | **Supabase (PostgreSQL)** | 사용자 사전 정보, 동행 파트너 정보 등 관계형 데이터 저장. |
| **Vector DB** | **Qdrant / FAISS** | 재난 대응 매뉴얼 벡터 데이터 저장 및 고속 검색. (Replit 환경 고려 시 Qdrant 추천) |
| **AI 서비스** | **OpenAI GPT-4** | RAG의 생성(Generation) 단계에서 최종 문장 구성. |
| **지도/경로** | **T Map API** | 대피소 위치 시각화 및 도보 경로 안내. |
| **재난 정보** | **재난안전데이터공유플랫폼 API** | 긴급재난문자(초기에는 모킹), 대피소 위치 정보 수신. |
| **알림/음성/진동** | **PWA Push, Web Speech API, Vibration API** | 브라우저 내장 기능을 활용한 핵심 UX 구현. |
| **다국어 처리** | **i18n-js** | 사용자의 언어 설정 기반 메시지 자동 변환. |
| **배포/개발** | **Replit** | 프론트엔드, 백엔드 동시 개발 및 배포 환경. |

-----

### 🧪 5. 기능별 세부 명세

#### **5.1. 사전 정보 입력 및 적응형 UI**

  * **입력 항목**: 나이, 성별, 사용 언어(ko, en, vi 등), 동행 파트너(이름, 연락처), 접근성 지원(아이콘 버튼: 기본, 시각 지원, 청각 지원).
  * **저장**: 모든 정보는 Supabase DB의 `users` 테이블에 저장.
  * **적응형 UI 규칙**:
      * **65세 이상**: 앱 전체 폰트 크기 1.5배 자동 증가.
      * **시각 지원**: 모든 화면 전환 및 주요 기능 실행 시 음성 안내(Web Speech API) 자동 활성화.
      * **청각 지원**: 모든 알림 및 주요 상호작용에 진동(Vibration API) 피드백 제공. `Vibration.vibrate([500, 1000, 500]);` 과 같은 패턴 활용.

#### **5.2. RAG 기반 초개인화 매뉴얼 생성 (핵심 로직)**

  * **목표**: AI의 환각(Hallucination) 현상을 방지하고, 신뢰할 수 있는 정보를 바탕으로 개인화된 안내를 제공.
  * **작동 방식**:
    1.  **정보 검색 (Retrieval)**: 사용자의 재난 상황(지진, 실내, 이동 불가)과 가장 관련성 높은 행동 요령을 사전 구축된 매뉴얼 Vector DB(Qdrant)에서 먼저 검색.
    2.  **정보 증강 (Augmented)**: 검색된 공식 매뉴얼 내용과 사용자의 모든 개인 정보(72세, 여성, 청각 지원 필요 등)를 결합하여 OpenAI API에 전달할 구체적이고 풍부한 프롬프트(명령어)를 구성.
    3.  **답변 생성 (Generation)**: 구성된 프롬프트를 기반으로 OpenAI가 최종적으로 사용자에게 가장 적합한 형태의 쉽고 간결한 맞춤형 매뉴얼을 생성.
  * **API Endpoint**: `POST /api/v1/manual/generate`
  * **Request Body**:
    ```json
    {
      "userId": "supabase-uid-abcde-12345",
      "disasterType": "earthquake",
      "preInfo": {
        "age": 72,
        "gender": "female",
        "language": "ko",
        "accessibility": "hearing",
        "partnerContact": "010-1234-5678"
      },
      "realtimeInfo": {
        "locationContext": "indoor",
        "canMove": false,
        "gps": { "lat": 37.5665, "lng": 126.9780 }
      }
    }
    ```
  * **Response Body**:
    ```json
    {
      "message": "현재 실내에 있으며 이동이 어렵습니다. 즉시 머리를 보호하고 튼튼한 탁자 아래로 몸을 피하세요. 진동이 멈춘 후 주변에 도움을 요청해야 합니다. 청각 지원 모드에 따라 강한 진동으로 주요 안내를 반복합니다.",
      "audioText": "You are indoors and cannot move. Protect your head and get under a sturdy table immediately. After the shaking stops, call for help...",
      "shelters": [
        { "name": "가나초등학교", "lat": 37.561, "lng": 126.998, "type": "옥외 대피소" },
        { "name": "다라공원", "lat": 37.563, "lng": 126.995, "type": "옥외 대피소" },
        { "name": "마바실내체육관", "lat": 37.559, "lng": 127.001, "type": "실내 구호소" }
      ]
    }
    ```

#### **5.3. 스마트 대피소 안내 및 SOS**

  * **지도**: T Map API를 사용하여 현재 위치 기준 가장 가까운 대피소 3곳을 마커로 표시. 마커 클릭 시 대피소 이름 표시, '길찾기' 버튼 클릭 시 T Map 도보 경로 안내 웹페이지로 연동.
  * **대피소 데이터**: `shelters.json` 또는 API를 통해 제공. 형식은 아래와 같음.
    ```json
    [
      { "name": "홍익초등학교", "lat": 37.561, "lng": 126.998, "type": "옥외 대피소" }
    ]
    ```
  * **SOS**: 화면에 항상 떠 있는 SOS 버튼 클릭 시, \*\*[119 신고]\*\*와 **[동행 파트너에게 알리기]** 옵션을 제공.
      * 119 신고: `window.location.href = 'tel:119';`
      * 파트너에게 알리기: `window.location.href = 'sms:010-1234-5678?body=긴급상황! 현재 위치: [GPS 기반 주소] 도움이 필요합니다.';`

-----

### 🧑‍💻 6. 개발 작업 구조 (디렉토리 예시)

#### **프론트엔드 (React / PWA)**

```
/frontend/
  ├── public/
  │   └── lang/
  │       └── en.json, ko.json, vi.json
  ├── src/
  │   ├── App.jsx
  │   ├── screens/
  │   │   ├── Peacetime/
  │   │   │   └── UserProfileScreen.jsx
  │   │   └── Disaster/
  │   │       ├── GuideScreen.jsx
  │   │       └── MapScreen.jsx
  │   ├── components/
  │   │   └── SOSButton.jsx
  │   ├── services/
  │   │   └── api.js          // Axios 또는 Fetch API
  │   │   └── tmap.js
  │   └── utils/
  │       └── i18n.js
  └── vite.config.js
```

#### **백엔드 (FastAPI)**

```
/backend/
  ├── main.py                 // FastAPI 앱 초기화
  ├── api/
  │   └── v1/
  │       └── manual.py       // /manual/generate 라우터
  ├── core/
  │   └── config.py           // 환경변수, 설정
  ├── rag/
  │   ├── retriever.py        // Vector DB 검색 로직
  │   ├── generator.py        // OpenAI 연동 및 프롬프트 구성
  ├── data/
  │   └── manuals.json        // 벡터화할 원본 매뉴얼 데이터
  └── requirements.txt
```

-----

### 📝 7. 개발 과업 우선순위 (PoC 로드맵)

| 순서 | 내용 | 담당 | 비고 |
| :--- | :--- | :--- | :--- |
| **1** | **기본 환경 구축** | 공통 | Replit에 React(Vite), FastAPI 기본 프로젝트 설정 |
| **2** | **사전 정보 입력 UI 및 DB 연동** | FE/BE | 사용자 프로필 입력 화면 구성 및 Supabase 연동 |
| **3** | **백엔드 RAG 파이프라인 구축 (1차)** | BE | `manuals.json` -\> Vector DB 임베딩, OpenAI 연동하여 텍스트 입/출력 API(`/manual/generate`) 완성 |
| **4** | **핵심 안내 흐름 연동** | FE/BE | 실시간 상태 입력 -\> 백엔드 API 호출 -\> 응답 텍스트 표시 |
| **5** | **스마트 대피소 안내 연동** | FE/BE | T Map API 연동하여 지도에 대피소 마커 표시 |
| **6** | **멀티모달 기능 구현** | FE | 응답 받은 텍스트를 Web Speech API로 음성 출력, Vibration API로 진동 구현 |
| **7** | **SOS 및 적응형 UI 구현** | FE | 긴급 요청(전화/문자) 기능 연동 및 접근성 규칙 적용 |
| **8** | **다국어 지원 및 고도화** | FE | i18n 라이브러리 적용 및 전체 UX 개선 |

-----

### ✅ 8. 성공 판단 기준 (PoC)

1.  **전체 흐름 검증**: [평시 정보 입력] → [재난 알림(모킹)] → [실시간 정보 입력] → [정보 통합] → [RAG 기반 맞춤형 결과 출력]의 전체 시나리오가 끊김 없이 작동하는가?
2.  **초개인화 검증**: 동일한 재난 상황에서, '청각 지원이 필요한 70대 사용자'와 '이동이 불가능한 30대 사용자'에게 각각 다른 내용과 형태(진동/음성)의 안내가 제공되는가?
3.  **신뢰도 검증**: 생성된 안내가 Vector DB에 저장된 공식 매뉴얼에 기반하며, AI가 임의로 지어낸 내용이 없는가? (RAG 성능)
4.  **핵심 기능 검증**: 적응형 UI, 대피소 지도 표시, 도보 경로 연동, 음성/진동 안내, SOS 기능이 모두 정상적으로 작동하는가?
5.  **다국어 검증**: 사용자가 설정한 언어(한국어, 영어 등)에 따라 UI와 최종 안내 메시지가 올바르게 변환되어 출력되는가?